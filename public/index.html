<!DOCTYPE html>
<html lang="te">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sahay - Prudence Health Assistant</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/react@18/umd/react.development.js"></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+Telugu:wght@400;700&display=swap');
        body { font-family: 'Noto Sans Telugu', sans-serif; background: #f8fafc; }
        .dot { animation: wave 1.3s linear infinite; }
        .dot:nth-child(2) { animation-delay: -1.1s; }
        .dot:nth-child(3) { animation-delay: -0.9s; }
        @keyframes wave { 0%, 60%, 100% { transform: initial; } 30% { transform: translateY(-5px); } }
    </style>
</head>
<body>
    <div id="root"></div>
    <script type="text/babel">
        const { useState, useEffect, useRef } = React;

        function App() {
            const [history, setHistory] = useState([
                { role: 'model', parts: [{ text: "నమస్కారం! నేను సహాయ్, మీ AI ఆరోగ్య సహాయకుడిని. నేను మీకు ఎలా సహాయపడగలను?" }] }
            ]);
            const [status, setStatus] = useState('idle');
            const [inputText, setInputText] = useState('');
            const chatEndRef = useRef(null);
            const audioRef = useRef(null);
            const recognitionRef = useRef(null);

            useEffect(() => { chatEndRef.current?.scrollIntoView({ behavior: "smooth" }); }, [history]);

            // NEW: Updated Voice Output to call our secure Netlify function
            const playVoice = async (text) => {
                setStatus('speaking');
                try {
                    const response = await fetch('/.netlify/functions/textToSpeech', {
                        method: 'POST',
                        body: JSON.stringify({ text }),
                    });
                    const data = await response.json();
                    if (data.audioContent) {
                        audioRef.current.src = `data:audio/mp3;base64,${data.audioContent}`;
                        audioRef.current.play();
                    } else {
                        setStatus('idle');
                    }
                } catch (error) {
                    console.error("TTS Error:", error);
                    setStatus('idle');
                }
            };

            const getAiReply = async (currentHistory) => {
                setStatus('thinking');
                try {
                    const response = await fetch('/.netlify/functions/getAiResponse', {
                        method: 'POST',
                        body: JSON.stringify({ history: currentHistory }),
                    });
                    const data = await response.json();
                    const aiReply = data.reply || "క్షమించండి.";
                    setHistory([...currentHistory, { role: 'model', parts: [{ text: aiReply }] }]);
                    playVoice(aiReply);
                } catch (error) {
                    setStatus('idle');
                }
            };

            const handleTextSubmit = (e) => {
                e.preventDefault();
                if (!inputText.trim() || status !== 'idle') return;
                const newHistory = [...history, { role: 'user', parts: [{ text: inputText }] }];
                setHistory(newHistory);
                setInputText('');
                getAiReply(newHistory);
            };

            useEffect(() => {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                if (!SpeechRecognition) return;
                const rec = new SpeechRecognition();
                rec.lang = 'te-IN';
                rec.onstart = () => setStatus('listening');
                rec.onend = () => setStatus('idle');
                rec.onresult = (e) => {
                    const text = e.results[0][0].transcript;
                    const newHistory = [...history, { role: 'user', parts: [{ text }] }];
                    setHistory(newHistory);
                    getAiReply(newHistory);
                };
                recognitionRef.current = rec;
            }, [history]);

            return (
                <div className="flex items-center justify-center min-h-screen p-4">
                    <audio ref={audioRef} onEnded={() => setStatus('idle')} className="hidden" />
                    <div className="w-full max-w-md h-[85vh] bg-white rounded-3xl shadow-xl flex flex-col overflow-hidden border">
                        <div className="bg-blue-600 p-6 text-white text-center">
                            <h1 className="font-bold uppercase tracking-widest text-sm">Prudence Hospitals</h1>
                            <p className="text-xs opacity-80">Sahay AI Assistant</p>
                        </div>
                        
                        <div className="flex-1 overflow-y-auto p-4 space-y-4 bg-gray-50">
                            {history.map((turn, i) => (
                                <div key={i} className={`flex ${turn.role === 'user' ? 'justify-end' : 'justify-start'}`}>
                                    <div className={`p-3 rounded-2xl max-w-[80%] text-sm ${turn.role === 'user' ? 'bg-blue-600 text-white' : 'bg-white border shadow-sm'}`}>
                                        {turn.parts[0].text}
                                    </div>
                                </div>
                            ))}
                            {status === 'thinking' && <div className="text-blue-500 text-xs">Sahay is thinking...</div>}
                            <div ref={chatEndRef} />
                        </div>

                        <div className="p-4 border-t flex gap-2 items-center">
                            <button 
                                onClick={() => recognitionRef.current?.start()}
                                className={`w-12 h-12 rounded-full flex items-center justify-center ${status === 'listening' ? 'bg-red-500 text-white animate-pulse' : 'bg-gray-100 text-gray-500'}`}
                            >
                                <i className="fas fa-microphone"></i>
                            </button>
                            <form onSubmit={handleTextSubmit} className="flex-1 flex gap-2">
                                <input 
                                    className="flex-1 border rounded-xl px-4 py-2 outline-none focus:border-blue-500"
                                    value={inputText}
                                    onChange={(e) => setInputText(e.target.value)}
                                    placeholder="Type in Telugu..."
                                    disabled={status !== 'idle'}
                                />
                                <button type="submit" className="bg-blue-600 text-white w-12 h-12 rounded-xl">
                                    <i className="fas fa-paper-plane"></i>
                                </button>
                            </form>
                        </div>
                    </div>
                </div>
            );
        }
        const root = ReactDOM.createRoot(document.getElementById('root'));
        root.render(<App />);
    </script>
</body>
</html>